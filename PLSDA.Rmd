---
title: "PLSDA"
author: "Adriana_Lecourieux"
date: "2022-10-10"
output: pdf_document
---
# Analyse supervisée
•Réaliser une PLSDA (Y = sample info)
•Comparer le graphe des échantillons de la PLSDA avec celui de la PCA.
•Lequel permet une meilleure séparation des classes ?

## 0. Load library and data
```{r}
library(mixOmics)
```

```{r}
data <-readRDS("data_tcga.Rds")
data_mRNA <- readRDS("mRNA_data_scaled.Rds")
data_mRNA <- as.data.frame(data_mRNA)
data_miRNA <- readRDS("miRNA_data_scaled.Rds")
data_miRNA <- as.data.frame(data_miRNA)
data_prot <- readRDS("prot_data_scaled.Rds")
data_prot <- as.data.frame(data_prot)
data_class <- data$sample_info

```

## 1. sPLSDA for mRNA

X = data_mRNA
Y = data_class$Y
```{r}
Y = data_class$Y
mRNA_splsda <- splsda(data_mRNA, Y, ncomp = 10)  # set ncomp to 10 for performance assessment later
```

### 1.1. Plot the samples projected onto the first two components of the PLS-DA subspace

```{r}
plotIndiv(mRNA_splsda , comp = 1:2, 
          group = Y, ind.names = FALSE,  # colour points by class
          ellipse = TRUE, # include 95% confidence ellipse for each class
          legend = TRUE, title = 'mRNA PLSDA with confidence ellipses')
```

Use the max.dist measure to form decision boundaries between classes based on PLS-DA data

```{r}
background = background.predict(mRNA_splsda, comp.predicted=2, dist = "max.dist")

```


Plot the samples projected onto the first two components of the PLS-DA subspace
```{r}
plotIndiv(mRNA_splsda, comp = 1:2,
          group = Y, ind.names = FALSE, # colour points by class
          background = background, # include prediction background for each class
          legend = TRUE, title = "mRNA PLSDA with prediction background")
```

Sample plots of the gene expression data after a basic PLS-DA model was operated on this data. 1. depicts the samples with the confidence ellipses of different class labels while 2. depicts the prediction background generated by these samples. Both plots use the first two components as axes.

### 1.2. Tuning sPLSDA

### 1.2.1. Select the number of components

Undergo performance evaluation in order to tune the number of components to use

```{r}
perf_splsda_mRNA <- perf(mRNA_splsda, validation = "Mfold", 
                          folds = 5, nrepeat = 10, # use repeated cross-validation
                          progressBar = FALSE, auc = TRUE) # include AUC values
```

Plot the outcome of performance evaluation across all ten components

```{r}
plot(perf_splsda_mRNA, col = color.mixo(5:7), sd = TRUE,
     legend.position = "horizontal")
```


```{r}
perf_splsda_mRNA$choice.ncomp # what is the optimal value of components according to perf()

```
Le nombre de composantes optimale est 3.

### 1.2.2. Select the number of variables

Grid of possible keepX values that will be tested for each component

```{r}
list.keepX <- c(1:10,  seq(20, 300, 10))
```

Undergo the tuning process to determine the optimal number of variables

```{r}
tune_splsda_mRNA <- tune.splsda(data_mRNA, Y, ncomp = 3, # calculate for first 3 components
                                 validation = 'Mfold',
                                 folds = 5, nrepeat = 10, # use repeated cross-validation
                                 dist = 'max.dist', # use max.dist measure
                                 measure = "BER", # use balanced error rate of dist measure
                                 test.keepX = list.keepX,
                                 cpus = 2) # allow for paralleliation to decrease runtime
```

Plot output of variable number tuning

```{r}
plot(tune_splsda_mRNA, col = color.jet(3))
```

```{r}
tune_splsda_mRNA$choice.ncomp$ncomp # what is the optimal value of components according to tune.splsda()
```
```{r}
tune_splsda_mRNA$choice.keepX # what are the optimal values of variables according to tune.splsda()

```

These values are stored to form the final, optimised model.
```{r}
optimal_ncomp_mRNA <- tune_splsda_mRNA$choice.ncomp$ncomp
optimal_keepX_mRNA <- tune_splsda_mRNA$choice.keepX[1:optimal_ncomp_mRNA]
```

### 1.2.3. Final Model

Form final model with optimised values for component and variable count
```{r}
final_splsda_mRNA <- splsda(data_mRNA, Y, 
                       ncomp = optimal_ncomp_mRNA, 
                       keepX = optimal_keepX_mRNA)
```

Plot

```{r}
plotIndiv(final_splsda_mRNA, comp = c(1,2), # plot samples from final model
          group = Y, ind.names = FALSE, # colour by class label
          ellipse = TRUE, legend = TRUE, # include 95% confidence ellipse
          title = 'sPLS-DA on mRNA, comp 1 & 2')
```

```{r}
plotIndiv(final_splsda_mRNA, comp = c(1,3), # plot samples from final model
          group = Y, ind.names = FALSE, # colour by class label
          ellipse = TRUE, legend = TRUE, # include 95% confidence ellipse
          title = 'sPLS-DA on mRNA, comp 1 & 3')
```

### 1.2.4. Cluster Image Map (CIM)

```{r}
# set the styling of the legend to be homogeneous with previous plots
legend=list(legend = levels(Y), # set of classes
            col = unique(color.mixo(Y)), # set of colours
            title = "Tumour Type", # legend title
            cex = 0.7) # legend size

# generate the CIM, using the legend and colouring rows by each sample's class
cim_mRNA <- cim(final_splsda_mRNA, row.sideColors = color.mixo(Y), 
           legend = legend)


save_and_plot <- function(dest_file, plot_function, ...){
  svg(dest_file)
  plot_function(...)
  dev.off()
}

save_and_plot("cim_mRNA_plsda", cim, final_splsda_mRNA, row.sideColors = color.mixo(Y), 
           legend = legend)
```

### 1.2.5. Correlation circle plot

```{r}
plotVar(final_splsda_mRNA, comp = c(1,2), var.names = list(colnames(data_mRNA)), cex = 3) # generate correlation circle plot
```

### 1.2.6. Prediction

Create training and testing dataset
```{r}
train_mRNA <- sample(1:nrow(data_mRNA), 50) # randomly select 50 samples in training
test_mRNA <- setdiff(1:nrow(data_mRNA), train_mRNA) # rest is part of the test set
```



```{r}
# store matrices into training and test set:
mRNA_train <- data_mRNA[train_mRNA, ]
mRNA_test <- data_mRNA[test_mRNA,]
Y_train_mRNA <- Y[train_mRNA]
Y_test_mRNA <- Y[test_mRNA]
```

Train the model
```{r}
train_splsda_mRNA <- splsda(mRNA_train, Y_train_mRNA, ncomp = optimal_ncomp_mRNA, keepX = optimal_keepX_mRNA)

```

Use the model on mRNA_test set
```{r}
predict_splsda_mRNA <- predict(train_splsda_mRNA, mRNA_test, 
                                dist = "mahalanobis.dist")
```

### 1.2.7. Prediction accuracy

```{r}
# evaluate the prediction accuracy for the first two components
predict_comp2_mRNA <- predict_splsda_mRNA$class$mahalanobis.dist[,2]
table(factor(predict_comp2_mRNA, levels = levels(Y)), Y_test_mRNA)
```

```{r}
# evaluate the prediction accuracy for the first three components
predict_comp3_mRNA <- predict_splsda_mRNA$class$mahalanobis.dist[,3]
table(factor(predict_comp3_mRNA, levels = levels(Y)), Y_test_mRNA)
```
### 1.2.8. Performance plots


```{r}
auc_splsda_mRNA = auroc(final_splsda_mRNA, roc.comp = 1, print = FALSE) # AUROC for the first component

```

```{r}
auc.splsda = auroc(final_splsda_mRNA, roc.comp = 3, print = FALSE) # AUROC for all three components

```

## 2. sPLSDA for miRNA

X = data_miRNA
Y = data_class$Y
```{r}
Y = data_class$Y
miRNA_splsda <- splsda(data_miRNA, Y, ncomp = 10)  # set ncomp to 10 for performance assessment later
```

### 1.1. Plot the samples projected onto the first two components of the PLS-DA subspace

```{r}
plotIndiv(miRNA_splsda , comp = 1:2, 
          group = Y, ind.names = FALSE,  # colour points by class
          ellipse = TRUE, # include 95% confidence ellipse for each class
          legend = TRUE, title = 'miRNA PLSDA with confidence ellipses')
```

Use the max.dist measure to form decision boundaries between classes based on PLS-DA data

```{r}
background = background.predict(miRNA_splsda, comp.predicted=2, dist = "max.dist")

```


Plot the samples projected onto the first two components of the PLS-DA subspace
```{r}
plotIndiv(miRNA_splsda, comp = 1:2,
          group = Y, ind.names = FALSE, # colour points by class
          background = background, # include prediction background for each class
          legend = TRUE, title = "miRNA PLSDA with prediction background")
```

Sample plots of the gene expression data after a basic PLS-DA model was operated on this data. 1. depicts the samples with the confidence ellipses of different class labels while 2. depicts the prediction background generated by these samples. Both plots use the first two components as axes.

### 1.2. Tuning sPLSDA

### 1.2.1. Select the number of components

Undergo performance evaluation in order to tune the number of components to use

```{r}
perf_splsda_miRNA <- perf(miRNA_splsda, validation = "Mfold", 
                          folds = 5, nrepeat = 10, # use repeated cross-validation
                          progressBar = FALSE, auc = TRUE) # include AUC values
```

Plot the outcome of performance evaluation across all ten components

```{r}
plot(perf_splsda_miRNA, col = color.mixo(5:7), sd = TRUE,
     legend.position = "horizontal")
```


```{r}
perf_splsda_miRNA$choice.ncomp # what is the optimal value of components according to perf()

```
Le nombre de composantes optimale est 6.

### 1.2.2. Select the number of variables

Grid of possible keepX values that will be tested for each component

```{r}
list.keepX <- c(1:10,  seq(20, 300, 10))
```

Undergo the tuning process to determine the optimal number of variables

```{r}
tune_splsda_miRNA <- tune.splsda(data_miRNA, Y, ncomp = 6, # calculate for first 3 components
                                 validation = 'Mfold',
                                 folds = 5, nrepeat = 10, # use repeated cross-validation
                                 dist = 'max.dist', # use max.dist measure
                                 measure = "BER", # use balanced error rate of dist measure
                                 test.keepX = list.keepX,
                                 cpus = 2) # allow for paralleliation to decrease runtime
```

Plot output of variable number tuning

```{r}
plot(tune_splsda_miRNA, col = color.jet(6))
```

```{r}
tune_splsda_miRNA$choice.ncomp$ncomp # what is the optimal value of components according to tune.splsda()
```

```{r}
tune_splsda_miRNA$choice.keepX # what are the optimal values of variables according to tune.splsda()

```

These values are stored to form the final, optimised model.
```{r}
optimal_ncomp_miRNA <- 6
optimal_keepX_miRNA <- tune_splsda_miRNA$choice.keepX[1:optimal_ncomp_miRNA]
```

### 1.2.3. Final Model

Form final model with optimised values for component and variable count
```{r}
final_splsda_miRNA <- splsda(data_miRNA, Y, 
                       ncomp = optimal_ncomp_miRNA, 
                       keepX = optimal_keepX_miRNA)
```

Plot

```{r}
plotIndiv(final_splsda_miRNA, comp = c(1,2), # plot samples from final model
          group = Y, ind.names = FALSE, # colour by class label
          ellipse = TRUE, legend = TRUE, # include 95% confidence ellipse
          title = 'sPLS-DA on miRNA, comp 1 & 2')
```

```{r}
plotIndiv(final_splsda_miRNA, comp = c(1,3), # plot samples from final model
          group = Y, ind.names = FALSE, # colour by class label
          ellipse = TRUE, legend = TRUE, # include 95% confidence ellipse
          title = 'sPLS-DA on miRNA, comp 1 & 3')
```
```{r}
plotIndiv(final_splsda_miRNA, comp = c(1,6), # plot samples from final model
          group = Y, ind.names = FALSE, # colour by class label
          ellipse = TRUE, legend = TRUE, # include 95% confidence ellipse
          title = 'sPLS-DA on miRNA, comp 1 & 6')
```

### 1.2.4. Cluster Image Map (CIM)

```{r}
# set the styling of the legend to be homogeneous with previous plots
legend=list(legend = levels(Y), # set of classes
            col = unique(color.mixo(Y)), # set of colours
            title = "Tumour Type", # legend title
            cex = 0.7) # legend size

# generate the CIM, using the legend and colouring rows by each sample's class
cim_miRNA <- cim(final_splsda_miRNA, row.sideColors = color.mixo(Y), 
           legend = legend)


save_and_plot <- function(dest_file, plot_function, ...){
  svg(dest_file)
  plot_function(...)
  dev.off()
}

save_and_plot("cim_miRNA_plsda", cim, final_splsda_miRNA, row.sideColors = color.mixo(Y), 
           legend = legend)
```

### 1.2.5. Correlation circle plot

```{r}
plotVar(final_splsda_miRNA, comp = c(1,2), var.names = list(colnames(data_miRNA)), cex = 3) # generate correlation circle plot
```
```{r}
plotVar(final_splsda_miRNA, comp = c(1,3), var.names = list(colnames(data_miRNA)), cex = 3)
```

### 1.2.6. Prediction

Create training and testing dataset
```{r}
train_miRNA <- sample(1:nrow(data_miRNA), 50) # randomly select 50 samples in training
test_miRNA <- setdiff(1:nrow(data_miRNA), train_miRNA) # rest is part of the test set
```



```{r}
# store matrices into training and test set:
miRNA_train <- data_miRNA[train_miRNA, ]
miRNA_test <- data_miRNA[test_miRNA,]
Y_train_miRNA <- Y[train_miRNA]
Y_test_miRNA <- Y[test_miRNA]
```

Train the model
```{r}
train_splsda_miRNA <- splsda(miRNA_train, Y_train_miRNA, ncomp = optimal_ncomp_miRNA, keepX = optimal_keepX_miRNA)

```

Use the model on miRNA_test set
```{r}
predict_splsda_miRNA <- predict(train_splsda_miRNA, miRNA_test, 
                                dist = "mahalanobis.dist")
```

### 1.2.7. Prediction accuracy

```{r}
# evaluate the prediction accuracy for the first two components
predict_comp2_miRNA <- predict_splsda_miRNA$class$mahalanobis.dist[,2]
table(factor(predict_comp2_miRNA, levels = levels(Y)), Y_test_miRNA)
```
```{r}
# evaluate the prediction accuracy for the first three components
predict_comp3_miRNA <- predict_splsda_miRNA$class$mahalanobis.dist[,3]
table(factor(predict_comp3_miRNA, levels = levels(Y)), Y_test_miRNA)
```


```{r}
# evaluate the prediction accuracy for the first three components
predict_comp3_miRNA <- predict_splsda_miRNA$class$mahalanobis.dist[,6]
table(factor(predict_comp3_miRNA, levels = levels(Y)), Y_test_miRNA)
```
### 1.2.8. Performance plots


```{r}
auc_splsda_miRNA = auroc(final_splsda_miRNA, roc.comp = 1, print = FALSE) # AUROC for the first component

```

```{r}
auc.splsda = auroc(final_splsda_miRNA, roc.comp = 3, print = FALSE) # AUROC for all three components

```


```{r}
auc.splsda = auroc(final_splsda_miRNA, roc.comp = 6, print = FALSE) # AUROC for all three components

```


Faire blabla pour dire que 6 composantes c'est statistiquement le paramètre otpimal mais que 3 suffisent.







## 3. sPLSDA for protein


X = data_prot
Y = data_class$Y
```{r}
Y = data_class$Y
prot_splsda <- splsda(data_prot, Y, ncomp = 10)  # set ncomp to 10 for performance assessment later
```

### 1.1. Plot the samples projected onto the first two components of the PLS-DA subspace

```{r}
plotIndiv(prot_splsda , comp = 1:2, 
          group = Y, ind.names = FALSE,  # colour points by class
          ellipse = TRUE, # include 95% confidence ellipse for each class
          legend = TRUE, title = 'prot PLSDA with confidence ellipses')
```

Use the max.dist measure to form decision boundaries between classes based on PLS-DA data

```{r}
background = background.predict(prot_splsda, comp.predicted=2, dist = "max.dist")

```


Plot the samples projected onto the first two components of the PLS-DA subspace
```{r}
plotIndiv(prot_splsda, comp = 1:2,
          group = Y, ind.names = FALSE, # colour points by class
          background = background, # include prediction background for each class
          legend = TRUE, title = "prot PLSDA with prediction background")
```

Sample plots of the gene expression data after a basic PLS-DA model was operated on this data. 1. depicts the samples with the confidence ellipses of different class labels while 2. depicts the prediction background generated by these samples. Both plots use the first two components as axes.

### 1.2. Tuning sPLSDA

### 1.2.1. Select the number of components

Undergo performance evaluation in order to tune the number of components to use

```{r}
perf_splsda_prot <- perf(prot_splsda, validation = "Mfold", 
                          folds = 5, nrepeat = 10, # use repeated cross-validation
                          progressBar = FALSE, auc = TRUE) # include AUC values
```

Plot the outcome of performance evaluation across all ten components

```{r}
plot(perf_splsda_prot, col = color.mixo(5:7), sd = TRUE,
     legend.position = "horizontal")
```


```{r}
perf_splsda_prot$choice.ncomp # what is the optimal value of components according to perf()

```
Le nombre de composantes optimale est 3.

### 1.2.2. Select the number of variables

Grid of possible keepX values that will be tested for each component

```{r}
list.keepX <- c(1:10,  seq(20, 300, 10))
```

Undergo the tuning process to determine the optimal number of variables

```{r}
tune_splsda_prot <- tune.splsda(data_prot, Y, ncomp = 3, # calculate for first 3 components
                                 validation = 'Mfold',
                                 folds = 5, nrepeat = 10, # use repeated cross-validation
                                 dist = 'max.dist', # use max.dist measure
                                 measure = "BER", # use balanced error rate of dist measure
                                 test.keepX = list.keepX,
                                 cpus = 2) # allow for paralleliation to decrease runtime
```

Plot output of variable number tuning

```{r}
plot(tune_splsda_prot, col = color.jet(3))
```

```{r}
tune_splsda_prot$choice.ncomp$ncomp # what is the optimal value of components according to tune.splsda()
```


```{r}
tune_splsda_prot$choice.keepX # what are the optimal values of variables according to tune.splsda()

```

These values are stored to form the final, optimised model.
```{r}
optimal_ncomp_prot <- 3
optimal_keepX_prot <- tune_splsda_prot$choice.keepX[1:optimal_ncomp_prot]
```

### 1.2.3. Final Model

Form final model with optimised values for component and variable count
```{r}
final_splsda_prot <- splsda(data_prot, Y, 
                       ncomp = optimal_ncomp_prot, 
                       keepX = optimal_keepX_prot)
```

Plot

```{r}
plotIndiv(final_splsda_prot, comp = c(1,2), # plot samples from final model
          group = Y, ind.names = FALSE, # colour by class label
          ellipse = TRUE, legend = TRUE, # include 95% confidence ellipse
          title = 'sPLS-DA on protein, comp 1 & 2')
```

```{r}
plotIndiv(final_splsda_prot, comp = c(1,3), # plot samples from final model
          group = Y, ind.names = FALSE, # colour by class label
          ellipse = TRUE, legend = TRUE, # include 95% confidence ellipse
          title = 'sPLS-DA on prot, comp 1 & 3')
```

### 1.2.4. Cluster Image Map (CIM)

```{r}
# set the styling of the legend to be homogeneous with previous plots
legend=list(legend = levels(Y), # set of classes
            col = unique(color.mixo(Y)), # set of colours
            title = "Tumour Type", # legend title
            cex = 0.7) # legend size

# generate the CIM, using the legend and colouring rows by each sample's class
cim_prot <- cim(final_splsda_prot, row.sideColors = color.mixo(Y), 
           legend = legend)


save_and_plot <- function(dest_file, plot_function, ...){
  svg(dest_file)
  plot_function(...)
  dev.off()
}

save_and_plot("cim_prot_plsda", cim, final_splsda_prot, row.sideColors = color.mixo(Y), 
           legend = legend)
```

### 1.2.5. Correlation circle plot

```{r}
plotVar(final_splsda_prot, comp = c(1,2), var.names = list(colnames(data_prot)), cex = 3) # generate correlation circle plot
```

### 1.2.6. Prediction

Create training and testing dataset
```{r}
train_prot <- sample(1:nrow(data_prot), 50) # randomly select 50 samples in training
test_prot <- setdiff(1:nrow(data_prot), train_prot) # rest is part of the test set
```



```{r}
# store matrices into training and test set:
prot_train <- data_prot[train_prot, ]
prot_test <- data_prot[test_prot,]
Y_train_prot <- Y[train_prot]
Y_test_prot <- Y[test_prot]
```

Train the model
```{r}
train_splsda_prot <- splsda(prot_train, Y_train_prot, ncomp = optimal_ncomp_prot, keepX = optimal_keepX_prot)

```

Use the model on prot_test set
```{r}
predict_splsda_prot <- predict(train_splsda_prot, prot_test, 
                                dist = "mahalanobis.dist")
```

### 1.2.7. Prediction accuracy

```{r}
# evaluate the prediction accuracy for the first two components
predict_comp2_prot <- predict_splsda_prot$class$mahalanobis.dist[,2]
table(factor(predict_comp2_prot, levels = levels(Y)), Y_test_prot)
```

```{r}
# evaluate the prediction accuracy for the first three components
predict_comp3_prot <- predict_splsda_prot$class$mahalanobis.dist[,3]
table(factor(predict_comp3_prot, levels = levels(Y)), Y_test_prot)
```
### 1.2.8. Performance plots


```{r}
auc_splsda_prot = auroc(final_splsda_prot, roc.comp = 1, print = FALSE) # AUROC for the first component

```

```{r}
auc.splsda = auroc(final_splsda_prot, roc.comp = 2, print = FALSE) # AUROC for all three components

```
```{r}
auc.splsda = auroc(final_splsda_prot, roc.comp = 3, print = FALSE) # AUROC for all three components

```
On choisi de prendre que 2 composantes pour obtenir le modèle le plus simple.